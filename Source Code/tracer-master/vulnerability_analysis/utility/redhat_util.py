#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
-----------------------------------------
@Created: 2021/02/14
------------------------------------------
@Modify: 2021/02/14
------------------------------------------
@Description:

"""
import os,sys,re
_PROJECT_NAME = 'VulnerabilityAnalysis'
_CURRENT_ABSPATH = os.path.abspath(__file__)
sys.path.insert(0, _CURRENT_ABSPATH[:_CURRENT_ABSPATH.find(_PROJECT_NAME) + len(_PROJECT_NAME) + 1])

from vulnerability_analysis import config
from vulnerability_analysis.utility import json_processing, log, file_processing
from vulnerability_analysis.utility import anlalyse_webcontent_util
from vulnerability_analysis.utility.crawler import crawl_util

crawled_redhat_vulnerability_comments_item_path =  config.CRAWLED_REDHAT_VULNERABILITY_COMMENTS_ITEM_PATH
crawled_redhat_vulnerability_item_path = config.CRAWLED_REDHAT_VULNERABILITIES_ITEM_PATH
crawled_redhat_vulnerability_webhtmL_item_path = config.CRAWLED_REDHAT_VULNERABILITIES_WEBHTML_ITEM_PATH
URL_REDHAT_BUG = config.URL_REDHAT_BUG
URL_REDHAT_BUG_COMMENTS = config.URL_REDHAT_BUG_COMMENTS
URL_REDHAT_BUG_WEBSITE = config.URL_REDHAT_BUG_WEBSITE


def get_refs_in_Redhat_report(CVEID, force_update=False):
    CVEItem_redhat_bug_report_comments_path = crawled_redhat_vulnerability_comments_item_path % CVEID
    CVEItem_redhat_bug_report_path = crawled_redhat_vulnerability_item_path % CVEID
    CVEItem_redhat_bug_report_webhtml_path = crawled_redhat_vulnerability_webhtmL_item_path % CVEID

    if force_update:
        url_redhat_bug_website = URL_REDHAT_BUG_WEBSITE % CVEID
        webhtml = crawl_util.request_and_judge_response(url=url_redhat_bug_website)
        if not webhtml: return None
        url_list, web_content = anlalyse_webcontent_util.extract_URLs_and_text(webhtml, url_redhat_bug_website)
        url_list = [ele.split('__fdse__')[0] + '__fdse__' + 'from comment content' for ele in url_list if
                    'attachment' in ele or 'from html content' in ele]
        return url_list
    # 不在DB中
    # 实验所需的数据应该都过了一遍。防止有些CVE在redhat中是缺失的，及时crawl也无法获取
    if not file_processing.pathExist(CVEItem_redhat_bug_report_webhtml_path): return None
    ## search DB
    if file_processing.pathExist(CVEItem_redhat_bug_report_webhtml_path):
        # 在DB中，说明该CVEID存在于redhat中； request redhat网页，提取所有的URL以及text
        # 1. by request website url
        url_redhat_bug_website = URL_REDHAT_BUG_WEBSITE % CVEID
        # url_list , web_content = request_and_anlalyse_webcontent.request_and_extract_URLs_and_text(url_redhat_bug_website)
        # 2. by loacl DB
        webhtml = file_processing.read_TXTfile(path=CVEItem_redhat_bug_report_webhtml_path)
        url_list, web_content = anlalyse_webcontent_util.extract_URLs_and_text(webhtml, url_redhat_bug_website)
        url_list = [ele.split('__fdse__')[0] + '__fdse__' + 'from comment content' for ele in url_list if
                    'attachment' in ele or 'from html content' in ele]
        return url_list
#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
-----------------------------------------
@Created: 2020/11/24
------------------------------------------
@Modify: 2020/11/24
------------------------------------------
@Description:


"""

import threading
import traceback
import multiprocessing

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as cond
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.common.keys import Keys

import random
import time
import os, sys, inspect

current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)
sys.path.append('../')
sys.path.append('../..')

import json
import time
import selenium
import psutil
from vulnerability_analysis import config
from selenium.webdriver.chrome.service import Service

# Chorme
# 关闭提示 "Chorme正在收到自动软件的控制"
# option = webdriver.ChromeOptions()
# option.add_argument('disable-infobars')
# 后台显示，前端不显示
# option.add_argument('headless')
# browser = webdriver.Chrome('/Users/congyingxu/Documents/chromedriver', chrome_options=option)
Chrome_driver_path = config.TOOL_CHROME_DRIVER

chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument("--enable-javascript")
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
# 使用headless无界面浏览器模式
chrome_options.add_argument('--headless')
# 增加无界面选项
chrome_options.add_argument('--disable-gpu')
# //如果不加这个选项，有时定位会出现问题
# chrome_options.add_argument("javascript.enabled")
# chrome_options.add_argument("--enable-javascript")



def start_browser():
    start_time = time.time()
    # 启动浏览器，获取网页源代码
    _browser = webdriver.Chrome(chrome_options=chrome_options)
    _browser.set_page_load_timeout(60)
    _browser.set_script_timeout(60)  # 这两种设置都进行才有效, 设置为5时， # mainUrl = 'https://bugs.eclipse.org/bugs/show_bug.cgi?id=539171' 访问不成功
    mainUrl = "https://www.taobao.com/"
    # mainUrl = 'http://krbdev.mit.edu/rt/Ticket/Display.html?id=7637'

    # _browser.get(mainUrl)
    # pageSource = _browser.page_source
    # html = pageSource.encode("utf-8", "ignore")
    end_time = time.time()
    print("browser start!", "time-consuming: ", end_time - start_time)
    print('PID_selenium_chrome_start:' + str(_browser.service.process.pid) + ':PID_end')
    return _browser

browser = start_browser()

def getHtmlFromUrl(url):
    global browser

    try:
        print('------------------------- url:' + url)
        browser.get(url)
        pageSource = browser.page_source
        html = pageSource.encode("utf-8", "ignore")
        title = browser.title
    except Exception as e:
        print("Exception:", e.__str__())
        time.sleep(5)
        restart()
        try:
            browser.get(url)
            pageSource = browser.page_source
            html = pageSource.encode("utf-8", "ignore")
            title = browser.title
        except Exception as e:
            print("Exception:", e.__str__())
            html = None
            title = None
    return html, title

# 增加了decode操作
def getHtmlFromUrl_decode(url):
    global browser

    try:
        print('------------------------- url:' + url)
        browser.get(url)
        pageSource = browser.page_source
        html = pageSource.encode("utf-8", "ignore").decode()
        title = browser.title
    except selenium.common.exceptions.TimeoutException:
        print("TimeoutException")
        time.sleep(10)

        restart()

        browser.get(url)
        pageSource = browser.page_source
        html = pageSource.encode("utf-8", "ignore").decode()
        title = browser.title

    return html, title

browser_lock = multiprocessing.Lock()

def crawl_with_decode_and_status_code(url):
    """ 返回 UTF-8 编码的 HTML 字符串与 Status Code. """
    global browser
    browser_lock.acquire()
    res = (-1000, None)
    for i in range(2):
        try:
            print('------------------------- url:' + url)
            browser.get(url)
            # WebDriverWait(browser, 10).until(cond.presence_of_element_located((By.ID, 'thread_0')))
            # time.sleep(5) # hacker等页面需要加载一下
            pageSource = browser.page_source
            raw = pageSource.encode("utf-8", "ignore").decode()
            res = (200, raw)
            print('------------------------- url(200):' + browser.current_url)
            break
        except selenium.common.exceptions.TimeoutException:
            print('------------------------- url(TimeoutException):' + browser.current_url )
            print("TimeoutException",traceback.format_exc())
            time.sleep(5)
            restart()
        except Exception as e:
            print('------------------------- url(Unknown Error):' + browser.current_url)
            print("Unknown Error",traceback.format_exc())
            time.sleep(5)
            restart()
            res = (-1, traceback.format_exc())
            break
    browser_lock.release()
    return res

def getHttpStatus(browser):
    for responseReceived in browser.get_log('performance'):
        try:
            response = json.loads(responseReceived[u'message'])[u'message'][u'params'][u'response']
            if response[u'url'] == browser.current_url:
                return response[u'status'], response[u'statusText']
        except:
            pass
    return None


def quitCrawler():
    global browser
    browser.quit()

def restart():
    global browser
    print("restart")
    quitCrawler()
    browser = start_browser()

def cases_test():
    url = 'https://bugs.eclipse.org/bugs/show_bug.cgi?id=539171'
    res = getHtmlFromUrl(url)
    print(res)


if __name__ == '__main__':
    # cases_test()
    # print(getHtmlFromUrl_decode('https://lists.apache.org/thread.html/a6a33a186f293f9f9aecf3bd39c76252bfc49a79de4321dd2a53b488@%3Csolr-user.lucene.apache.org%3E'))
    # print(crawl_with_decode_and_status_code('https://lists.apache.org/thread.html/r36e44ffc1a9b365327df62cdfaabe85b9a5637de102cea07d79b2dbf@%3Ccommits.cxf.apache.org%3E'))
    url = 'https://www.atlassian.com/'
    crawl_with_decode_and_status_code(url)
